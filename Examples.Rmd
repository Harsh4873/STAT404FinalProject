```{r}
# Visualize Theoretical Sampling Distributions (Harsh Dave)

# The below content gives an example of how to use the functions in the package sim_funcs.R. Each section corresponds to a specific function with different scenarios to show the range of outputs.

# Core Simulation Functions

## simulation_of_binary_response

### Single Group Example

# Shows how to simulate binary responses with a single probability and sample size:
# simulation_of_binary_response(p = 0.5, n = 100)

### Additional Example

# Shows simulation with a different probability:
# simulation_of_binary_response(p = 0.7, n = 200) 

## simulation_for_two_sample_data

### Small Difference

# Simulates two samples with a small difference in proportions: 
# simulation_for_two_sample_data(p1 = 0.4, p2 = 0.45, n1 = 100, n2 = 100)

### Large Difference

# Simulates two samples with a significant difference in proportions: 
# simulation_for_two_sample_data(p1 = 0.2, p2 = 0.7, n1 = 200, n2 = 200)

# calculate_the_difference_in_proportions

### Low difference

# Calculates the difference in proportions for a scenario with a low difference: 
# calculate_the_difference_in_proportions(p1 = 0.3, p2 = 0.35, n1 = 100, n2 = 100)

### Big difference

# Calculates the difference in proportions for a scenario with a big difference: 
# calculate_the_difference_in_proportions(p1 = 0.1, p2 = 0.6, n1 = 200, n2 = 200)

# repeated_simulations_for_one_simulation

# Small sample, few repetitions

# Runs simulations with small sample sizes and fewer repetitions: 
# repeated_simulations_for_one_simulation(p1 = 0.3, p2 = 0.4, n1 = 50, n2 = 50, rep_steps = c(10, 50, 100))

# Large sample, many repetitions 

# Runs simulations with large sample sizes and numerous repetitions: 
# repeated_simulations_for_one_simulation(p1 = 0.2, p2 = 0.5, n1 = 500, n2 = 500, rep_steps = c(100, 500, 1000, 5000, 10000))

# Sampling Distribution Visualization

# Small sample visualization

# Visualizes the sampling distribution for small samples: 
# visualize_theoretical_sampling_distribution(p1 = 0.3, p2 = 0.4, n1 = 50, n2 = 50)

# Visualizes the sampling distribution for large samples: 
# visualize_theoretical_sampling_distribution(p1 = 0.2, p2 = 0.5, n1 = 500, n2 = 500)



# Confidence Analysis Examples (Ritvik V)

# The purpose of this package is to facilitate simulations and visualizations of statistical concepts related to confidence intervals and sampling distributions. The primary function, # visualize_confidence_levels, simulates repeated sampling for two groups with specified proportions and sample sizes. It calculates confidence intervals for the difference in # proportions and visualizes the proportion of intervals that capture the true difference.

# Simple Example:
# library(ggplot2)

# visualize_confidence_levels(
#  p1 = 0.6,  
#  p2 = 0.5,
#  n1 = 30,   
#  n2 = 30,   
#  rep_steps = c(10, 50, 100, 500, 1000))

# The expected output is a line plot showing the proportion of confidence intervals that include the true difference in proportions.

# Test Case for smaller sample sizes:

# Smaller sample sizes tend to have wider confidence intervals, making it harder for the intervals to contain the true difference.

# Example:
# visualize_confidence_levels(
#  p1 = 0.6, p2 = 0.5,
#  n1 = 10, n2 = 10,
#  rep_steps = c(10, 50, 100, 500, 1000))

# This plot will show slower convergence to the theoretical level compared to larger sample sizes.

# Test Case for different significance values:

# Changing the significance level affects the width of the confidence intervals. Smaller significance results in more conservative intervals.

# Example:

# visualize_confidence_levels(
#  p1 = 0.6, p2 = 0.5,
#  n1 = 30, n2 = 30,
#  rep_steps = c(10, 50, 100, 500, 1000),
#  alpha = 0.01)

# We can expect the proportions to converge to 99%

# Error handling examples:

# invalid proportions:
# visualize_confidence_levels(p1 = 1.5, p2 = 0.5, n1 = 30, n2 = 30, rep_steps = c(10, 50))
# The error is that proportions p1 and p2 must be between 0 and 1

# negative sample size:
# visualize_confidence_levels(p1 = 0.6, p2 = 0.5, n1 = -30, n2 = 30, rep_steps = c(10, 50))
# The error is that sample sizes n1 and n2 must be positive integers


# Permutation Tests (Race Zwieg)

# These tests are intended to redistribute the group numbers along the observations and calculate the statistic of interest.
# The purpose of these tests is to see if there is a distinctive difference between the observed test statistic and the reallocated test statistic.

# Below are a few examples of the Permutation tests in action:

# Good example: 
# set.seed(2)
# n = 50
# p1 = 0.6
# p2 = 0.4
# responses = c(rbinom(n, 1, p1), rbinom(n, 1, p2))
# group.labels = c(rep(1, n), rep(2, n))
# permutation_test(group.labels, responses, num_reps = 1000)
    # This returns an accurate graphical depiction of the density curve over the test statistic vs denisty

# Bad Example:
# set.seed(3)
# n = 50
# p1 = 0.6
# p2 = 0.4
# responses = c(rbinom(n, 1, p1), rbinom(n, 1, p2))
# group.labels = c(rep(1, n), rep(2, n))
# permutation_test(group.labels, responses, num_reps = -5)
  # Returns: Error in permutation_test(group.labels, responses, num_reps = -5) : 
  #          Can not have negative permutations

# test.that("Permutation test works", permutation.test(c(rep(1, n), rep(2, n)), c(rbinom(n, 1, .4), rbinom(n, 1, .6)), num.reps = 1000))

# Bootstrapping (Christopher Coleman)
# These functions are intended to perform the bootstrapping algorithm to calculate simulated test statistics and visualize their differences
# The purpose of these functions is to attempt to create a theoretical confidence interval without mathematical derivation of a function for our parameters.

# Examples

# Bootstrapping algorithm with good input
# x1 <- 10
# n1 <- 20
# x2 <- 15
# n2 <- 25
#result <- calc_bootstrap_stats(x1, n1, x2, n2)

# returns a list of lists of everything used in the bootstrap calculations needed for visualization
# specifically, lists of the difference between simulated statistics, theoretical SE, bootstrap SE, theoretical CI, bootstrap CI, bootstrap differences, and confidence level 

# Bootstrapping algorithm with bad input

# x1 <- 10
# n1 <- 20
# x2 <- 15
# n2 <- -25
# result <- calc_bootstrap_stats(x1, n1, x2, n2)

# Returns: Error in calc_bootstrap_stats(x1, n1, x2, n2) : 
#          Number of observations (n1, n2) must be greater than zero.

# Visualization (takes input from the result list)

# x1 <- 10
# n1 <- 20
# x2 <- 15
# n2 <- 25
# result <- calc_bootstrap_stats(x1, n1, x2, n2)

# visualize_bootstrap_stats(result$bootstrap_diffs, result$CI_theoretical, result$CI_bootstrap)

# produces a graph showing the difference between the theoretical CI and bootstrap CI
```
